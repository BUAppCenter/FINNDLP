{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Streaming Dataflow Accelerator\n",
    "\n",
    "<font color=\"red\">**Live FINN tutorial:** 이 노트북을 읽기 시작할 때 **Cell -> Run All**을 클릭하는 것을 권장합니다.\n",
    "이를 통해 지연(latency) 숨김 효과를 얻을 수 있습니다.</font>\n",
    "\n",
    "**중요: 이 노트북은 1-train-mlp-with-brevitas 노트북에 의존합니다.\n",
    "해당 노트북에서 생성된 모델 파일(.onnx) 을 사용하고 있기 때문입니다.\n",
    "따라서, 이 노트북을 실행하기 전에 필요한 .onnx 파일들이 먼저 생성되어 있는지 확인해 주세요.**\n",
    "\n",
    "<img align=\"left\" src=\"../finn-example.png\" alt=\"drawing\" style=\"margin-right: 20px\" width=\"250\"/>\n",
    "\n",
    "이 노트북에서는 FINN 컴파일러를 사용하여, 사이버 보안 작업을 위한 양자화된 MLP 모델로부터 Streaming Dataflow 아키텍처 기반의 FPGA 가속기를 생성할 것입니다.\n",
    "이 아키텍처의 핵심 아이디어는, 레이어 간 병렬화뿐만 아니라 각 레이어 내에서도 병렬화하여, 각 레이어에 비례한 연산 자원을 할당하는 것입니다. (왼쪽 그림에 나타난 구조)\n",
    "이 개념에 대한 자세한 내용은 FINN 논문과 FINN-R 논문에서 확인할 수 있습니다.\n",
    "\n",
    "이를 위해 각 레이어를 Vivado HLS (High-Level Synthesis)로 변환하고, 각 레이어가 요구하는 병렬화 수준에 맞춰 구현한 뒤, On-Chip FIFO를 사용해 레이어들을 연결하여 전체 가속기를 구성합니다.\n",
    "\n",
    "이러한 방식은 성능과 유연성의 균형을 제공하지만, 수작업으로 구현하기에는 매우 어렵고 시간이 많이 소요됩니다.\n",
    "그래서 FINN 컴파일러가 필요한 것입니다.\n",
    "FINN 컴파일러는 ONNX 포맷의 모델을 입력받아, 원하는 처리량(Throughput)에 맞는 Streaming Dataflow 가속기를 자동으로 생성해줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "-------------\n",
    "\n",
    "1. [Introduction to  `build_dataflow` Tool](#intro_build_dataflow) \n",
    "2. [Understanding the Build Configuration: `DataflowBuildConfig`](#underst_build_conf)     \n",
    "    2.1.[Output Products](#output_prod)   \n",
    "    2.2.[Configuring the Board and FPGA Part](#config_fpga)   \n",
    "    2.3 [Configuring the Performance](#config_perf)    \n",
    "4. [Launch a Build: Only Estimate Reports](#build_estimate_report)\n",
    "5. [Launch a Build: Stitched IP, out-of-context synth and rtlsim Performance](#build_ip_synth_rtlsim)\n",
    "6. [(Optional) Launch a Build: PYNQ Bitfile and Driver](#build_bitfile_driver)\n",
    "7. [(Optional) Run on PYNQ board](#run_on_pynq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Introduction to  `build_dataflow` Tool <a id=\"intro_build_dataflow\"></a>\n",
    "\n",
    "버전 0.5b부터 FINN 컴파일러는 `build_dataflow` 도구를 제공한다. 이전 버전에서는 모든 필요한 변환 과정을 Python 스크립트로 직접 설정해야 했던 것과 달리, 이 도구를 통해 데이터플로우 아키텍처 생성을 보다 쉽게 실험할 수 있다. 핵심 개념은 관련 빌드 정보를 설정한 구성 `dict`를 제공하면, 필요한 모든 단계가 자동으로 수행되어 데이터플로우 빌드가 진행된다는 것이다. 이 도구는 [command line](https://finn-dev.readthedocs.io/en/latest/command_line.html) 에서 실행하거나, Python 함수 한 줄로 호출할 수 있다.\n",
    "\n",
    "\n",
    "이 노트북에서는 Jupyter 노트북 내에서 작업을 계속하기 위해 Python 함수 호출 방식을 사용하여 빌드를 실행할 것이다. 그러나 여기서 수행하는 작업을 `./run-docker.sh build_dataflow` 또는 `./run-docker.sh build_custom` 명령어를 사용해 명령줄에서 재현해보는 것도 자유롭게 시도해도 좋다.\n",
    "\n",
    "build_dataflow 도구 소개 <a id=\"intro_build_dataflow\"></a>\n",
    "버전 0.5b부터, FINN 컴파일러는 build_dataflow 도구를 제공합니다.\n",
    "이전 버전에서는 Python 스크립트 내에서 필요한 모든 변환을 직접 설정해야 했던 것과 달리,\n",
    "이 도구를 사용하면 Dataflow 아키텍처 생성을 보다 쉽게 실험할 수 있습니다.\n",
    "\n",
    "핵심 아이디어는, 필요한 빌드 정보를 하나의 구성 dict로 지정하면,\n",
    "Dataflow 빌드를 수행하는 데 필요한 모든 단계를 자동으로 실행해준다는 것입니다.\n",
    "이 도구는 커맨드 라인에서 실행할 수도 있고,\n",
    "단일 Python 함수 호출로도 실행할 수 있습니다.\n",
    "\n",
    "이 노트북에서는 Jupyter Notebook 환경을 유지하기 위해 Python 함수 호출 방식으로 빌드를 진행하겠지만,\n",
    "원한다면 여기서 진행하는 작업을\n",
    "./run-docker.sh build_dataflow 와 ./run-docker.sh build_custom 커맨드라인 명령어로도 시도해볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 빌드 설정 이해하기: `DataflowBuildConfig` <a id=\"underst_build_conf\"></a>\n",
    "\n",
    "빌드 설정은`finn.builder.build_dataflow_config.DataflowBuildConfig` 인스턴스를 통해 지정한다. 이 설정은 Python의 [`dataclass`](https://docs.python.org/3/library/dataclasses.html) 로 정의되어 있으며, JSON 파일로 직렬화하거나 역직렬화하여 저장할 수도 있다. 그러나 여기서는 Python 코드에서 직접 설정할 것이다.\n",
    "설정에는 빌드의 다양한 측면을 커스터마이즈할 수 있는 많은 옵션들이 포함되어 있지만, 이 노트북에서는 그중 일부만 다룰 것이다. 모든 설정 옵션에 대한 자세한 내용은 [FINN API 문서](https://finn-dev.readthedocs.io/en/latest/source_code/finn.builder.html#finn.builder.build_dataflow_config.DataflowBuildConfig).에서 확인할 수 있다.\n",
    "\n",
    "`DataflowBuildConfig`의 일부 구성 요소를 살펴보자:\n",
    "\n",
    "### 출력물 <a id=\"output_prod\"></a>\n",
    "\n",
    "빌드 과정에서는 다양한 출력물을 생성할 수 있으며, 일부 출력물은 시간이 오래 걸릴 수 있다 (예: 대규모 네트워크에 대한 비트파일 합성). 새로운 가속기 생성 작업을 시작하고 다양한 성능 옵션을 탐색할 때는 처음부터 비트파일까지 생성할 필요가 없을 수도 있다. 따라서 초반에는 추정 보고서(Estimate Reports)만 출력물로 선택하는 것이 일반적이다. 이후 설계가 만족스러워질 때까지 점진적으로 다음 단계의 출력물을 생성하고, 최종적으로는 쉘에 통합된 전체 가속기까지 빌드할 수 있다.\n",
    "\n",
    "The output products are controlled by:\n",
    "\n",
    "* `generate_outputs`: 빌드 과정에서 생성할 출력물의 목록. 각각의 출력물은[`finn.builder.build_dataflow_config.DataflowOutputType`](https://finn-dev.readthedocs.io/en/latest/source_code/finn.builder.html#finn.builder.build_dataflow_config.DataflowOutputType)) 타입이다. 사용 가능한 옵션 일부는 다음과 같다:\n",
    "    - `ESTIMATE_REPORTS` : 합성 없이, 각 레이어 및 전체 네트워크에 대한 예상 리소스 사용량과 성능을 보고서 형태로 제공\n",
    "    - `STITCHED_IP` : 다른 Vivado IPI 또는 RTL 디자인에 통합할 수 있는 스트림 입력-출력 IP 디자인 생성\n",
    "    - `RTLSIM_PERFORMANCE` : PyVerilator를 사용하여 STITCHED_IP 디자인의 성능 및 지연 시간 테스트 수행\n",
    "    - `OOC_SYNTH` : 주변 시스템 없이 가속기 자체만을 대상으로 Out-of-Context 합성 수행하여 합성 이후의 FPGA 리소스 사용량 및 달성 가능한 클럭 주기 확인\n",
    "    - `BITFILE` : 가속기를 쉘에 통합하여 독립 실행형 비트파일 생성\n",
    "    - `PYNQ_DRIVER` : 가속기 실행에 사용할 수 있는 PYNQ Python 드라이버 생성\n",
    "    - `DEPLOYMENT_PACKAGE` : `BITFILE`과 `PYNQ_DRIVER`를 포함하는 폴더 생성, 대상 FPGA 플랫폼에 복사하여 바로 사용할 수 있도록 구성\n",
    "* `output_dir`: 위의 빌드 출력물들이 저장될 디렉터리\n",
    "* `steps`: FINN이 빌드 과정에서 수행할 사전 정의된 (또는 커스텀) 빌드 단계 목록. 추정 단계만 실행하려면`build_dataflow_config.estimate_only_dataflow_steps` 를 사용하고, 그렇지 않으면 기본값인 `build_dataflow_config.default_build_dataflow_steps` 를 사용한다. 기본 빌드 단계 목록은 [여기](https://finn.readthedocs.io/en/latest/source_code/finn.builder.html#finn.builder.build_dataflow_config.default_build_dataflow_steps) 에서 확인할 수 있다.\n",
    "\n",
    "### 보드 및 FPGA 파트 설정 <a id=\"config_fpga\"></a>\n",
    "\n",
    "* `fpga_part`: 합성(Synthesis)에 사용할 Xilinx FPGA 파트. 아래의 `board` 설정으로부터 추론할 수 있으며, 특정 상황에서는 명시적으로 지정할 수도 있다 (예: Out-of-Context 합성).\n",
    "* `board`: 가속기를 쉘(Shell)에 통합하여 생성할 때 사용할 대상 Xilinx Zynq 또는 Alveo 보드. 사용 가능한 보드 목록은 [이 파일](https://github.com/Xilinx/finn-base/blob/dev/src/finn/util/basic.py#L41) 의`pynq_part_map` 및 `alveo_part_map` 딕셔너리를 참고.\n",
    "* `shell_flow_type`: FINN 디자인을 쉘에 통합하여 전체 비트파일(Bitfile)을 생성할 때 사용하는 [shell flow type](https://finn-dev.readthedocs.io/en/latest/source_code/finn.builder.html#finn.builder.build_dataflow_config.ShellFlowType), `BITFILE` 생성 옵션을 선택한 경우에만 필요하다.\n",
    "\n",
    "### 성능 설정 <a id=\"config_perf\"></a>\n",
    "\n",
    "생성된 데이터플로우 가속기의 성능(그리고 이에 따른 FPGA 리소스 사용량)은 두 가지 방법으로 설정할 수 있다:\n",
    "\n",
    "1) (기본) 목표 성능을 설정하면, 컴파일러가 각 노드별 병렬화 설정을 자동으로 결정한다.\n",
    "\n",
    "2) (고급) 각 레이어에 대한 병렬화 정도와 기타 하드웨어 옵션을 명시한 별도의 .json 파일을 `folding_config_file`로 지정한다.\n",
    "\n",
    "이 노트북에서는 기본 방법만 다루며, 이를 위해 다음과 같은 설정이 필요하다:\n",
    "\n",
    "* `target_fps`: 초당 프레임 수(frames per second) 기준의 목표 추론 성능. 특정 레이어 제약이나 FPGA 자원 한계로 인해 설정한 목표 성능이 달성되지 않을 수 있다.\n",
    "* synth_clk_period_ns: Vivado 합성을 위한 목표 클럭 주기(ns 단위). 예를 들어, synth_clk_period_ns=5.0으로 설정하면 200 MHz 클럭을 목표로 한다. 그러나 FPGA 파트나 설계 복잡도에 따라 해당 클럭 주기가 달성되지 않을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 빌드 실행: 추정 보고서만 생성 <a id=\"build_estimate_report\"></a>\n",
    "\n",
    "먼저, 우리는 추정 보고서(Estimate Reports)만 생성하는 빌드를 실행할 것이다. 이 빌드는 합성(Synthesis)을 필요로 하지 않는다. 아래 두 가지에 주목하라: `generate_outputs`가 `ESTIMATE_REPORTS`만 포함하고 있으며, `steps`에서는 `estimate_only_dataflow_steps` 값을 사용하고 있다. 이는 HLS 합성(HLS synthesis)과 같은 단계를 건너뛰고, 분석 모델(analytical models)을 통해 빠른 추정을 제공하기 위함이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous run results deleted!\n"
     ]
    }
   ],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "model_dir = os.environ['FINN_ROOT'] + \"/notebooks/end2end_example/cybersecurity/custom\"\n",
    "# model_file = model_dir + \"/cybsec-mlp-ready.onnx\"\n",
    "model_file = model_dir + \"/plz_work.onnx\"\n",
    "\n",
    "estimates_output_dir = \"plz_output\"\n",
    "\n",
    "# 경로가 존재하면 삭제한다\n",
    "if os.path.exists(estimates_output_dir):\n",
    "    shutil.rmtree(estimates_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "\n",
    "cfg_estimates = build.DataflowBuildConfig(\n",
    "    output_dir          = estimates_output_dir, # 결과 저장 폴더\n",
    "    mvau_wwidth_max     = 50, #MVAU (행렬-벡터 곱 유닛) 최대 가중치 폭 제한 (자원 제어)\n",
    "    target_fps          = 5000, #원하는 추론 속도 목표\n",
    "    synth_clk_period_ns = 5.0, #합성 시 사용될 클럭 주기 (5ns = 200MHz 클럭)\n",
    "    fpga_part           = \"xc7z020clg400-1\", # 사용할 FPGA 칩\n",
    "    steps               = build_cfg.estimate_only_dataflow_steps, # 실제 빌드 하지 않고, 자원 사용량/ 속도 등 추정만 수행\n",
    "    generate_outputs=[ # 리포트만 생성\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from /home/cloud9/finn/notebooks/end2end_example/cybersecurity/custom/plz_work.onnx\n",
      "Intermediate outputs will be generated in /tmp/finn_dev_cloud9\n",
      "Final outputs will be generated in plz_output\n",
      "Build log is at plz_output/build_dataflow.log\n",
      "Running step: step_qonnx_to_finn [1/10]\n",
      "Running step: step_tidy_up [2/10]\n",
      "Running step: step_streamline [3/10]\n",
      "Running step: step_convert_to_hw [4/10]\n",
      "Running step: step_create_dataflow_partition [5/10]\n",
      "Running step: step_specialize_layers [6/10]\n",
      "Running step: step_target_fps_parallelization [7/10]\n",
      "Running step: step_apply_folding_config [8/10]\n",
      "Running step: step_minimize_bit_width [9/10]\n",
      "Running step: step_generate_estimate_reports [10/10]\n",
      "Completed successfully\n",
      "CPU times: user 924 ms, sys: 1.45 s, total: 2.37 s\n",
      "Wall time: 585 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, cfg_estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(estimates_output_dir + \"/report/estimate_network_performance.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 이번 빌드 과정에서 생성된 출력 결과들을 살펴보겠습니다.\n",
    "outputs 디렉토리를 확인해보면, 그 안에 생성된 추정 리포트(estimate reports) 가 포함된 하위 폴더가 있는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_folding_config.json  report\n",
      "build_dataflow.log\t  template_specialize_layers_config.json\n",
      "intermediate_models\t  time_per_step.json\n"
     ]
    }
   ],
   "source": [
    "! ls {estimates_output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate_layer_config_alternatives.json  estimate_network_performance.json\n",
      "estimate_layer_cycles.json\t\t op_and_param_counts.json\n",
      "estimate_layer_resources.json\n"
     ]
    }
   ],
   "source": [
    "! ls {estimates_output_dir}/report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러 개의 리포트가 .json 파일 형식으로 생성된 것을 확인할 수 있습니다.\n",
    "먼저, `estimate_network_performance.json` 파일의 내용을 살펴보겠습니다.\n",
    "이 파일에는 성능(Throughput)과 지연 시간(Latency)에 대한 분석 기반 추정치가 포함되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"critical_path_cycles\": 24640,\n",
      "  \"max_cycles\": 16384,\n",
      "  \"max_cycles_node_name\": \"MVAU_hls_0\",\n",
      "  \"estimated_throughput_fps\": 12207.03125,\n",
      "  \"estimated_latency_ns\": 123200.0\n",
      "}"
     ]
    }
   ],
   "source": [
    "! cat {estimates_output_dir}/report/estimate_network_performance.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이러한 리포트들은 모두 .json 파일 형식이기 때문에,\n",
    "Python에서 쉽게 불러와서 추가적으로 가공하거나 분석할 수 있습니다.\n",
    "이는 만약 사용자가 FINN 위에 자체적인 자동화 도구(design automation tool)를 구축하려 할 때 유용하게 활용될 수 있습니다.\n",
    "\n",
    "이제, 이를 위해 헬퍼 함수를 정의하고,\n",
    "`estimate_layer_cycles.json` 리포트의 내용을 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def read_json_dict(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        ret = json.load(f)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3307163787.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    read_json_dict(estimates_output_dir + \"/report/estimate_layer_cycles.json\")python3 filter_Off.py -f restored_image.jpg\u001b[0m\n\u001b[0m                                                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "read_json_dict(estimates_output_dir + \"/report/estimate_layer_cycles.json\")python3 filter_Off.py -f restored_image.jpg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서는 각 레이어가 소요할 것으로 예상되는 클럭 사이클 수를 확인할 수 있습니다.\n",
    "모든 레이어는 병렬로 실행되기 때문에,\n",
    "가장 느린 레이어의 실행 시간이 전체 신경망의 처리량(Throughput) 을 결정하게 됩니다.\n",
    "\n",
    "FINN은 각 레이어가 비슷한 클럭 사이클 수를 가지도록 병렬화를 시도하며,\n",
    "설정된 `target_fps` (목표 프레임 속도) 를 달성하는 데 필요한 사이클 수보다 더 적게 소요되도록 조정합니다.\n",
    "\n",
    "또한, 모든 레이어의 추정 사이클 수를 합산하면\n",
    "전체 네트워크의 추정 지연 시간(Latency) 을 확인할 수 있습니다.\n",
    "\n",
    "마지막으로, 레이어별 FPGA 자원 사용량(Resource usage) 에 대한 추정치는\n",
    "`estimate_layer_resources.json` 리포트에서 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MVAU_hls_0': {'BRAM_18K': 8,\n",
       "  'BRAM_efficiency': 0.8888888888888888,\n",
       "  'LUT': 429,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'MVAU_hls_1': {'BRAM_18K': 4,\n",
       "  'BRAM_efficiency': 0.8888888888888888,\n",
       "  'LUT': 429,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'MVAU_hls_2': {'BRAM_18K': 1,\n",
       "  'BRAM_efficiency': 0.027777777777777776,\n",
       "  'LUT': 428,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'total': {'BRAM_18K': 13.0, 'LUT': 1286.0, 'URAM': 0.0, 'DSP': 0.0}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_json_dict(estimates_output_dir + \"/report/estimate_layer_resources.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 리포트는 현재 설정이 특정 FPGA에 적합한지 판단할 때 매우 유용합니다.\n",
    "만약 리포트에서 나타나는 자원 요구량이 사용하려는 FPGA의 한계보다 높은 경우,\n",
    "`target_fps` 값을 낮춰서 자원 요구량을 줄이는 것을 고려해야 합니다.\n",
    "\n",
    "**주의할 점은, 이 리포트의 분석 모델은 실제보다 자원 사용량을 과대 추정하는 경향이 있다는 것입니다.\n",
    "이는 합성(Synthesis) 과정에서 이루어지는 다양한 최적화 효과를\n",
    "모델이 정확히 반영하지 못하기 때문입니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 빌드 실행 단계: Stitched IP, Out-of-Context Synthesis, RTL Simulation 성능 측정 <a id=\"build_ip_synth_rtlsim\"></a>\n",
    "\n",
    "만족스러운 추정 결과가 나왔다면, 이제 가속기(Accelerator)를 실제로 생성하는 단계로 넘어갈 수 있습니다.\n",
    "가속기 생성 방식은, 이를 더 큰 시스템에 어떻게 통합할 것인지에 따라 여러 가지로 선택할 수 있습니다.\n",
    "\n",
    "예를 들어:\n",
    "\n",
    "Vivado에서 구축한 스트리밍 시스템에 통합하거나\n",
    "\n",
    "다른 프로젝트에서 재사용 가능한 IP(지적 재산) 컴포넌트로 사용하고자 할 경우\n",
    "→ STITCHED_IP 출력물을 생성하는 것이 좋은 선택입니다.\n",
    "\n",
    "또한, 생성된 가속기의 합성 이후(Post-synthesis)의 자원 사용량 및 클럭 주파수 정보를 얻고 싶다면\n",
    "OOC_SYNTH 출력물을 사용할 수 있습니다.\n",
    "\n",
    "<font color=\"red\">**Live FINN tutorial:** 다음 빌드 과정은 Vivado를 여러 번 호출하고 RTL 시뮬레이션을 수행하기 때문에 약 10분 정도 소요됩니다.\n",
    "빌드가 진행되는 동안, noVNC를 통해 생성된 파일들을 확인할 수 있습니다 — noVNC는 현재 실행 중입니다. **(your AWS URL):6080/vnc.html**\n",
    "\n",
    "* 아래의 `step_hls_codegen [8/16]` 단계가 완료되면, 각 레이어별로 생성된 HLS 코드를 해당 폴더에서 확인할 수 있다: `/tmp/finn_dev_ubuntu/code_gen_ipgen_MVAU_hls_XXXXXX`\n",
    "    \n",
    "* 아래의 `step_create_stitched_ip [11/16]` 단계가 완료되면, Vivado에서 생성된 Stitched IP를 다음 경로에서 확인할 수 있다:`/home/ubuntu/finn/notebooks/end2end_example/cybersecurity/output_ipstitch_ooc_rtlsim/stitched_ip`\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous run results deleted!\n"
     ]
    }
   ],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "model_file = model_dir + \"/plz_work.onnx\"\n",
    "\n",
    "rtlsim_output_dir = \"plz_word_output_ipstitch_ooc_rtlsim\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(rtlsim_output_dir):\n",
    "    shutil.rmtree(rtlsim_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "#고급 빌드 설정\n",
    "cfg_stitched_ip = build.DataflowBuildConfig(\n",
    "    output_dir          = rtlsim_output_dir, #출력 결과 저장 위치\n",
    "    mvau_wwidth_max     = 40, # 위와 같음\n",
    "    target_fps          = 5000, #위와 같음\n",
    "    synth_clk_period_ns = 5.0, # 위와 같음\n",
    "    fpga_part           = \"xc7z020clg400-1\", # 같음\n",
    "    generate_outputs=[ #어떤 빌드 단계를 수행할지 지정하는 리스트\n",
    "        #HSL로 생성된 각 계층을 IP로 만들고 IP연결까지 수행\n",
    "        build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "        # 실제 RTL레벨 시뮬레이션을 통해 정확한 성능 예측 수행\n",
    "        build_cfg.DataflowOutputType.RTLSIM_PERFORMANCE,\n",
    "        # Vivado에서 Out-Of-Context 방식으로 합성 수행 -> LUT, DSP, BRAM 사용량 추정\n",
    "        build_cfg.DataflowOutputType.OOC_SYNTH,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from /home/cloud9/finn/notebooks/end2end_example/cybersecurity/custom/plz_work.onnx\n",
      "Intermediate outputs will be generated in /tmp/finn_dev_cloud9\n",
      "Final outputs will be generated in plz_word_output_ipstitch_ooc_rtlsim\n",
      "Build log is at plz_word_output_ipstitch_ooc_rtlsim/build_dataflow.log\n",
      "Running step: step_qonnx_to_finn [1/19]\n",
      "Running step: step_tidy_up [2/19]\n",
      "Running step: step_streamline [3/19]\n",
      "Running step: step_convert_to_hw [4/19]\n",
      "Running step: step_create_dataflow_partition [5/19]\n",
      "Running step: step_specialize_layers [6/19]\n",
      "Running step: step_target_fps_parallelization [7/19]\n",
      "Running step: step_apply_folding_config [8/19]\n",
      "Running step: step_minimize_bit_width [9/19]\n",
      "Running step: step_generate_estimate_reports [10/19]\n",
      "Running step: step_hw_codegen [11/19]\n",
      "Running step: step_hw_ipgen [12/19]\n",
      "Running step: step_set_fifo_depths [13/19]\n",
      "Running step: step_create_stitched_ip [14/19]\n",
      "Running step: step_measure_rtlsim_performance [15/19]\n",
      "Running step: step_out_of_context_synthesis [16/19]\n",
      "Running step: step_synthesize_bitfile [17/19]\n",
      "Running step: step_make_pynq_driver [18/19]\n",
      "Running step: step_deployment_package [19/19]\n",
      "Completed successfully\n",
      "Success\n",
      "CPU times: user 2.38 s, sys: 1.65 s, total: 4.03 s\n",
      "Wall time: 10min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, cfg_stitched_ip)\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(rtlsim_output_dir + \"/report/ooc_synth_and_timing.json\")\n",
    "assert os.path.exists(rtlsim_output_dir + \"/report/rtlsim_performance.json\")\n",
    "assert os.path.exists(rtlsim_output_dir + \"/final_hw_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어, 우리가 출력물로 bitfile을 요청하지 않았는데도 위에 `step_synthesize_bitfile` 이 나열된 이유는 무엇일까요?\n",
    "이는 우리가 기본 빌드 단계(default set of build steps) 를 사용하고 있기 때문입니다.\n",
    "기본 단계에는 `step_synthesize_bitfile` 도 포함되어 있지만,\n",
    "출력물로 bitfile이 선택되지 않았기 때문에 이 단계는 실제로 아무 작업도 수행하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출력물들 중에는, Stitched IP 블록 디자인 형태로 내보내진 가속기(Accelerator) 가 포함되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_verilog_srcs.txt\t\t       finn_vivado_stitch_proj.xpr\n",
      "data\t\t\t\t       ip\n",
      "finn_vivado_stitch_proj.cache\t       make_project.sh\n",
      "finn_vivado_stitch_proj.gen\t       make_project.tcl\n",
      "finn_vivado_stitch_proj.hw\t       vivado.jou\n",
      "finn_vivado_stitch_proj.ip_user_files  vivado.log\n",
      "finn_vivado_stitch_proj.srcs\n"
     ]
    }
   ],
   "source": [
    "! ls {rtlsim_output_dir}/stitched_ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또한, 이번 출력물들에 의해 생성된 몇 가지 리포트(report) 도 있습니다.\n",
    "이 리포트들은 이전에 생성된 `ESTIMATE_REPORTS` 와는 다른 종류의 리포트입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate_layer_resources_hls.json  rtlsim_performance.json\n",
      "ooc_synth_and_timing.json\n"
     ]
    }
   ],
   "source": [
    "! ls {rtlsim_output_dir}/report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ooc_synth_and_timing.json` 파일에서는 가속기의 합성 이후(Post-synthesis) 정보와 최대 클럭 주파수 추정치를 확인할 수 있습니다.\n",
    "단, 여기서 제공되는 클럭 주파수 추정치는 제약 조건이 덜 적용된 Out-of-Context 합성 환경에서 나온 것이기 때문에, 다소 낙관적으로(over-estimate) 표시될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"vivado_proj_folder\": \"/tmp/finn_dev_cloud9/synth_out_of_context_kqvyvp8m/results_finn_design_wrapper\",\n",
      "  \"LUT\": 17342.0,\n",
      "  \"LUTRAM\": 56.0,\n",
      "  \"FF\": 13144.0,\n",
      "  \"DSP\": 0.0,\n",
      "  \"BRAM\": 140.0,\n",
      "  \"BRAM_18K\": 268.0,\n",
      "  \"BRAM_36K\": 6.0,\n",
      "  \"URAM\": 0.0,\n",
      "  \"Carry\": 1600.0,\n",
      "  \"WNS\": -2.153,\n",
      "  \"Delay\": -2.153,\n",
      "  \"vivado_version\": 2024.1,\n",
      "  \"vivado_build_no\": 5076996.0,\n",
      "  \"\": 0,\n",
      "  \"fmax_mhz\": 139.8014818957081,\n",
      "  \"estimated_throughput_fps\": 8532.80529148609\n",
      "}"
     ]
    }
   ],
   "source": [
    "! cat {rtlsim_output_dir}/report/ooc_synth_and_timing.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`rtlsim_performance.json` 파일에서는 RTL 시뮬레이션(rtlsim) 을 통해 얻은 가속기의 안정 상태 처리량(Steady-state throughput) 과 지연 시간(Latency) 을 확인할 수 있습니다.\n",
    "여기서 보고된 DRAM 대역폭(Bandwidth) 수치가 실제 하드웨어 플랫폼이 제공하는 대역폭보다 낮다면\n",
    "(즉, 가속기가 메모리 대역폭에 의해 병목되지 않는다면)\n",
    "실제 하드웨어에서도 동일한 처리량(소프트웨어/드라이버 오버헤드 제외)을 기대할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"N_IN_TXNS\": 128,\n",
      "  \"N_OUT_TXNS\": 1,\n",
      "  \"cycles\": 24476,\n",
      "  \"N\": 1,\n",
      "  \"latency_cycles\": 24476,\n",
      "  \"runtime[ms]\": 0.12238,\n",
      "  \"throughput[images/s]\": 8171.269815329302,\n",
      "  \"fclk[mhz]\": 200.0,\n",
      "  \"stable_throughput[images/s]\": 8171.269815329302\n",
      "}"
     ]
    }
   ],
   "source": [
    "! cat {rtlsim_output_dir}/report/rtlsim_performance.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로, `final_hw_config.json` 파일을 확인해봅시다.\n",
    "이 파일에는 FINN 컴파일러가 결정한 노드별 하드웨어 구성 정보가 담겨 있습니다.\n",
    "여기에는 FIFO 깊이(FIFO depths), 병렬화 설정 (PE/SIMD) 등 다양한 설정 값들이 포함되어 있습니다.\n",
    "\n",
    "추가로 빌드를 더 최적화(Advanced Method) 하고 싶다면,\n",
    "이 .json 파일을 `folding_config_file` 로 지정하여\n",
    "새로운 빌드를 시작할 때 출발점으로 활용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Defaults\": {},\n",
      "  \"StreamingFIFO_rtl_0\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 128,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"MVAU_hls_0\": {\n",
      "    \"PE\": 1,\n",
      "    \"SIMD\": 1,\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"resType\": \"auto\",\n",
      "    \"mem_mode\": \"internal_decoupled\",\n",
      "    \"runtime_writeable_weights\": 0,\n",
      "    \"inFIFODepths\": [\n",
      "      128\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      61\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_1\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 61,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"MVAU_hls_1\": {\n",
      "    \"PE\": 1,\n",
      "    \"SIMD\": 1,\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"resType\": \"auto\",\n",
      "    \"mem_mode\": \"internal_decoupled\",\n",
      "    \"runtime_writeable_weights\": 0,\n",
      "    \"inFIFODepths\": [\n",
      "      61\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      2\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_2\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 2,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"MVAU_hls_2\": {\n",
      "    \"PE\": 1,\n",
      "    \"SIMD\": 1,\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"resType\": \"auto\",\n",
      "    \"mem_mode\": \"internal_decoupled\",\n",
      "    \"runtime_writeable_weights\": 0,\n",
      "    \"inFIFODepths\": [\n",
      "      2\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      2\n",
      "    ]\n",
      "  },\n",
      "  \"StreamingFIFO_rtl_3\": {\n",
      "    \"ram_style\": \"auto\",\n",
      "    \"depth\": 2,\n",
      "    \"impl_style\": \"rtl\",\n",
      "    \"inFIFODepths\": [\n",
      "      0\n",
      "    ],\n",
      "    \"outFIFODepths\": [\n",
      "      0\n",
      "    ]\n",
      "  }\n",
      "}"
     ]
    }
   ],
   "source": [
    "! cat {rtlsim_output_dir}/final_hw_config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) 빌드 실행: PYNQ Bitfile 및 드라이버 생성 <a id=\"build_bitfile_driver\"></a>\n",
    "\n",
    "<font color=\"red\">**Live FINN tutorial:** 이 섹션은 Bitfile 합성 시간(약 15~20분) 으로 인해 핸즈온 튜토리얼에는 포함되어 있지 않습니다.\n",
    "만약 본인이 PYNQ 보드를 보유하고 있다면,\n",
    "튜토리얼 이후에 아래 셀들의 주석을 해제하여 직접 실행해볼 것을 권장합니다.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous run results deleted!\n",
      "??\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###########################################################\n",
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# model_file = model_dir + \"/cybsec-mlp-ready.onnx\"\n",
    "model_file = model_dir +\"/plz_work.onnx\"\n",
    "\n",
    "final_output_dir = \"plz_work_output_final\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(final_output_dir):\n",
    "    shutil.rmtree(final_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "# 실제 빌드\n",
    "cfg = build.DataflowBuildConfig(\n",
    "    output_dir          = final_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    target_fps          = 100000,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    board               = \"Pynq-Z2\",\n",
    "    # Vivado Zynq용 흐름 선택 (Zynq SoC용 Vivado build)\n",
    "    shell_flow_type     = build_cfg.ShellFlowType.VIVADO_ZYNQ,\n",
    "    generate_outputs=[\n",
    "        #Vivado를 이용해 FPGA용 bitstream (.bit)파일 생성\n",
    "        build_cfg.DataflowOutputType.BITFILE,\n",
    "        # PYNQ python에서 사용할 수 있는 드라이버 파일 생성\n",
    "        # PYNQ에서 Python코드로 모델 실행 가능\n",
    "        build_cfg.DataflowOutputType.PYNQ_DRIVER,\n",
    "        # 위의 파일들을 하나의 배포용 압축 패키지로 정리\n",
    "        build_cfg.DataflowOutputType.DEPLOYMENT_PACKAGE,\n",
    "    ]\n",
    ")\n",
    "print(\"??\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from /home/cloud9/finn/notebooks/end2end_example/cybersecurity/custom/plz_work.onnx\n",
      "Intermediate outputs will be generated in /tmp/finn_dev_cloud9\n",
      "Final outputs will be generated in plz_work_output_final\n",
      "Build log is at plz_work_output_final/build_dataflow.log\n",
      "Running step: step_qonnx_to_finn [1/19]\n",
      "Running step: step_tidy_up [2/19]\n",
      "Running step: step_streamline [3/19]\n",
      "Running step: step_convert_to_hw [4/19]\n",
      "Running step: step_create_dataflow_partition [5/19]\n",
      "Running step: step_specialize_layers [6/19]\n",
      "Running step: step_target_fps_parallelization [7/19]\n",
      "Running step: step_apply_folding_config [8/19]\n",
      "Running step: step_minimize_bit_width [9/19]\n",
      "Running step: step_generate_estimate_reports [10/19]\n",
      "Running step: step_hw_codegen [11/19]\n",
      "Running step: step_hw_ipgen [12/19]\n",
      "Running step: step_set_fifo_depths [13/19]\n",
      "Running step: step_create_stitched_ip [14/19]\n",
      "Running step: step_measure_rtlsim_performance [15/19]\n",
      "Running step: step_out_of_context_synthesis [16/19]\n",
      "Running step: step_synthesize_bitfile [17/19]\n",
      "Running step: step_make_pynq_driver [18/19]\n",
      "Running step: step_deployment_package [19/19]\n",
      "Completed successfully\n",
      "CPU times: user 1.83 s, sys: 2.01 s, total: 3.84 s\n",
      "Wall time: 29min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종 빌드에서는 출력물로 Bitfile과 함께,\n",
    "Zynq 플랫폼의 PYNQ에서 올바르게 실행하기 위해 필요한 `.hwh` 파일도 포함되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finn-accel.bit\tfinn-accel.hwh\n"
     ]
    }
   ],
   "source": [
    "! ls {final_output_dir}/bitfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생성된 Python 드라이버를 사용하면, PYNQ 플랫폼에서 단순히 NumPy 입력/출력으로 가속기를 실행할 수 있습니다.\n",
    "실행 시 FINN으로 생성된 가속기를 어떻게 사용하는지에 대한 예제 노트북들은 [finn-examples](https://github.com/Xilinx/finn-examples) 저장소에서 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driver_base.py\tdriver.py  finn  qonnx\truntime_weights  validate.py\n"
     ]
    }
   ],
   "source": [
    "! ls {final_output_dir}/driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reports 폴더에는 합성 이후(Post-synthesis)의 자원 사용량(Resource)과 타이밍(Timing) 리포트가 포함되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate_layer_resources_hls.json  post_synth_resources.json\n",
      "post_route_timing.rpt\t\t   post_synth_resources.xml\n"
     ]
    }
   ],
   "source": [
    "! ls {final_output_dir}/report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로, `deploy` 폴더에는 가속기를 실행하기 위해 대상 보드에 복사해야 할 모든 파일이 포함되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitfile  driver\n"
     ]
    }
   ],
   "source": [
    "! ls {final_output_dir}/deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Run on PYNQ board <a id=\"run_on_pynq\"></a>\n",
    "\n",
    "<font color=\"red\">**Live FINN tutorial:** 이 섹션은 이전 섹션에서의 Bitfile 합성 시간(약 15~20분) 으로 인해 핸즈온 튜토리얼에는 포함되어 있지 않습니다.\n",
    "만약 본인이 PYNQ 보드를 보유하고 있다면,\n",
    "튜토리얼 이후에 아래 셀들의 주석을 해제하여 직접 실행해볼 것을 권장합니다.</font>\n",
    "\n",
    "보드에서 가속기를 테스트하기 위해,\n",
    "데이터셋의 사본과 정확도 검증을 위한 Python 스크립트를 `driver` 폴더에 복사한 뒤,\n",
    "전체 배포 폴더(deploy 폴더) 를 ZIP 아카이브로 압축합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp unsw_nb15_binarized.npz {final_output_dir}/deploy/driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp validate-unsw-nb15.py {final_output_dir}/deploy/driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! ls {final_output_dir}/deploy/driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cloud9/finn/notebooks/end2end_example/cybersecurity/custom/deploy-on-pynq.zip'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shutil import make_archive\n",
    "make_archive('deploy-on-pynq', 'zip', final_output_dir+\"/deploy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 생성된 zip 파일을 다운로드할 수 있습니다 (**File -> Open**에서 `deploy-on-pynq.zip` 파일 옆의 체크박스를 선택한 후 툴바에서 Download를 클릭), 그런 다음 해당 파일을 PYNQ 보드로 복사하세요 (예: `scp` 또는` rsync` 사용).\n",
    "그 후, PYNQ 보드에서 다음 명령어를 실행하여 아카이브를 추출하고 검증을 수행하세요:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "unzip deploy-on-pynq.zip -d finn-cybsec-mlp-demo\n",
    "cd finn-cybsec-mlp-demo/driver\n",
    "sudo python3.6 -m pip install bitstring\n",
    "sudo python3.6 validate-unsw-nb15.py --batchsize 1000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막에 `Final accuracy: 91.868293` 이 출력되는 것을 확인할 수 있습니다.\n",
    "또한, 검증 과정에서 초당 100만 번의 추론 속도가 완전히 달성되지 않는 것을 눈치챘을 수도 있습니다.\n",
    "이는 Python의 데이터 패킹/언패킹 처리 및 데이터 이동 오버헤드 때문입니다.\n",
    "\n",
    "더 자세히 확인하고 싶다면, 생성된 드라이버에 포함된 벤치마킹 모드를 사용하면\n",
    "실행 시간의 세부 분해(runtime breakdown) 를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "sudo python3.6 driver.py --exec_mode throughput_test --bitfile ../bitfile/finn-accel.bit --batchsize 1000\n",
    "cat nw_metrics.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{'runtime[ms]': 1.0602474212646484,\n",
    " 'throughput[images/s]': 943176.0737575893,\n",
    " 'DRAM_in_bandwidth[Mb/s]': 70.7382055318192,\n",
    " 'DRAM_out_bandwidth[Mb/s]': 0.9431760737575894,\n",
    " 'fclk[mhz]': 100.0,\n",
    " 'batch_size': 1000,\n",
    " 'fold_input[ms]': 9.679794311523438e-05,\n",
    " 'pack_input[ms]': 0.060115814208984375,\n",
    " 'copy_input_data_to_device[ms]': 0.002428770065307617,\n",
    " 'copy_output_data_from_device[ms]': 0.0005249977111816406,\n",
    " 'unpack_output[ms]': 0.3773000240325928,\n",
    " 'unfold_output[ms]': 6.818771362304688e-05}```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 여러 번 나타나는 `pack_input/unpack_output` 호출은\n",
    "입출력 데이터를 numpy 배열에서 가속기가 기대하는 비트 연속 데이터 형식으로 변환할 때 발생하는 패킹/언패킹 오버헤드를 보여줍니다.\n",
    "또한, `copy_input_data_to_device` 와 `copy_output_data_from_device` 는\n",
    "데이터를 CPU와 가속기 메모리 사이에서 이동시키는 데 소요되는 비용을 나타냅니다.\n",
    "\n",
    "이러한 오버헤드는 배치 크기(batch size)가 작은 경우 실행 시간의 대부분을 차지할 수 있습니다.\n",
    "\n",
    "마지막으로, `throughput[images/s]` 값은\n",
    "소프트웨어 및 데이터 이동 오버헤드 없이 순수한 하드웨어 처리량을 나타내며,\n",
    "초당 약 100만 번의 추론(1M inferences per second) 에 근접한 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
